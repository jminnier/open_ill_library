---
title: "Open Access Button - a Vignette"
author: "Jessica Minnier"
date: '`r Sys.Date()`'
output:   
  github_document:
    toc: yes
---


```{r setup, include=FALSE}
library(tidyverse)
library(readxl)
library(skimr)
library(janitor)
library(here)
library(glue)
library(printr)
#### Global chunk options -----------------------------

knitr::opts_chunk$set(
  eval       = TRUE,    # whether to run code in code chunk
  include    = TRUE,    # whether to include the chunk output
  echo       = TRUE,   # Whether to show code chunk in final output
  error      = TRUE,    # whether to display error messages
  message    = FALSE,   # whether to preserve messages
  warning    = FALSE,   # whether to preserve warnings
  comment    = "#>",    # a character string to append at start
                        # of each line of results in final document
  tidy       = FALSE,   # whether to tidy code chunks for display
  dpi        = 96, 
  fig.width  = 6,       # consistent width for figures
  fig.asp    = 0.618,   # the golden ratio, can be adjusted in individual chunks
  out.width  = "100%",   # controls the output size
  fig.align  = "center" # give plot room to breathe
)
```

# Introduction and Background

I have been working on a project led by [Robin Champieux](https://github.com/rchampieux) of the OHSU Library that examines the utility of open access search tools such as Unpaywall and Open Access Button in inter-library loan (ILL) queries. I used the APIs from these tools to query a list of articles and determine whether there was an open access version of that article available. Here, I go through a short vignette showing how you can do this yourself.

The Unpaywall API can be queried using the R package [roadoi](https://github.com/ropensci/roadoi). As far as I know, the open access button does not yet have a package that can query it the same way. So, let's try using API tools in R.

Note: you must have internet access for this to run.

## Open Access Button

The [Open Access (OA) Button](https://openaccessbutton.org/) can be installed as an extension to your web browser so that when you are on a website for an article, the the button alerts you to an open access version of that article that you can view without an expensive subscription to publisher and academic journal content. Tools like OA button and Unpaywall are making headway in making science results accessible to all.

## APIs

API is an acronym for application programming interface. We can use APIs to gather a large amount of information based on queries sent to a database that is hosted in a particular website. It's like sending a question to a website and getting an answer back in a standardized format. A good introduction to API can be found on [Zapier](https://zapier.com/learn/apis/).

I used this [helpful blog post](http://tophcito.blogspot.com/2015/11/accessing-apis-from-r-and-little-r.html) by Christoph Waldhauser to get me started in querying APIs using R. Much of the code in this vignette can be found in that blog post.

## DOIs

We will be using DOIs (digital object identifiers) to query articles. DOIs are useful because they are unique and standardized ways of identifying scholarly articles, books, software, photographs, and other objects. The ROpenSci R package [`rcrossref`](https://github.com/ropensci/rcrossref) is a great way to explore articles using the Crossref metadata search API. We will be using this package to generate and query DOIs for articles.

## JSON

[JSON](https://en.wikipedia.org/wiki/JSON) (JavaScript Object Notation) is a file and format that provides array data types in a string of text. APIs return query results in JSON format.


# Packages

We will use the R packages `urltools`, `httr`, `jsonlite` to query the API and process the JSON data that is returned from the API. We will also use ROpenSci's package [`rcrossref`](https://github.com/ropensci/rcrossref) to generate some DOIs and look up some information about articles.

```{r}
# install.packages(c("urltools","httr","jsonlite","rcrossref"))
library(urltools)
library(httr)
library(jsonlite)
library(rcrossref)
```


# OA Button API

Take a look at the website for [OA button API](https://openaccessbutton.org/api), and familiarize yourself with the possible types of queries. We will be using the `GET` query to search `availibility`.

Note that OA Button wants you to use an apikey. You should generate yoru own apikey and use it for queries. As of now, this is not enforced, so we can still run queries without one, but it's good practice to use a key so that you can be identified.

# Practice

Let's try a blank query to the API:

```{r}
oa_url  <- "https://api.openaccessbutton.org" # url of the API
path <- "/" # blank path for testing

# A blank query. Get the result in JSON
raw_result <- GET(url = oa_url, path = path)
raw_result #JSON output
```

This just lets us know we've reached the right URL (https://api.openaccessbutton.org/). Now what if we try a hello world? There's an article with "Hello World" in the title that happens to be open access (thanks NIH!) and we can see the citation using `rcrossref::cr_cn`:

```{r}
rcrossref::cr_cn(dois="10.1007/s10278-018-0079-6",format="text",style="apa")
```

Now let's query the OA button API with the article's doi:

```{r}
path <- "/availability?url=10.1007/s10278-018-0079-6" # url path

# A blank query. Get the result in JSON
raw_result <- GET(url = oa_url, path = path)
raw_result #JSON output
```

What's going on here? We are using the `httr::GET` function to obtain the result from the API with a certain url. The url we are querying is https://api.openaccessbutton.org/availability?url=10.1007/s10278-018-0079-6. We construct this url by adding the path "/availability?url=10.1007/s10278-018-0079-6" to the API url "https://api.openaccessbutton.org". If we click on this link https://api.openaccessbutton.org/availability?url=10.1007/s10278-018-0079-6, our browser will show us the JSON output.

So, is this article available via open access, or not? It looks like there's something in the "availibility" field, but it's hard to see the data when it's in this not-quite-readable JSON format. Let's clean it up a bit. The output of `GET` is an object of type "raw" but JSON is by nature a string, so we will use `rawToChar` function to turn it into a character string. Then, `jsonlite::fromJSON` will process the JSON string into a list of lists.

```{r}
str(raw_result$content)
this_raw_content <- rawToChar(raw_result$content)
str(this_raw_content)
```

What does `fromJSON` give us?

```{r}
this_content <- jsonlite::fromJSON(this_raw_content)
str(this_content)
```

`this_content` is a list, with one element called `data`, which is also a list. We can extract the data frame from showing availibility:

```{r}
this_content$data$availability
```

If we click on this link http://europepmc.org/backend/ptpmcrender.fcgi?accid=PMC5959832&blobtype=pdf we can see the article as a pdf, freely available for all to read!

# Query and Extract Functions

All of this pasting together urls and DOIs and processing strings is a bit cumbersome and will easily become repetitive when we query a list of articles. We can write some functions that use our query as an input (i.e. a DOI or an article title) and outputs the availibility data frame.

## makePath

This function takes our query as an input and outputs the URL we use in `GET`. Since we may want to query a title which may have spaces, we use `urltools::url_encode` to convert the title into a URL friendly string.

We add the parameter `queryname` since some searches can be improved by specifying which type of query we are using, such as "doi" or "title", though the default "url" works well in most cases.

We leave an option to add your `apikey` if you have it.

Not familiar with `glue::glue`? Check out the [readme](https://github.com/tidyverse/glue) on github.

```{r}
makePath <- function(query, 
                      path="availability",
                      queryname="url", # can be more specific such as "doi" or "title"
                      apikey = NULL) {
  query <- urltools::url_encode(query)
  pathout <- glue::glue("{path}?{queryname}={query}")
  if(!is.null(apikey)) {pathout <- glue::glue("{pathout}&apikey={apikey}")} # use an apikey if we have it
  return(pathout)
}
```


```{r}
(my_path <- makePath(query="10.1007/s10278-018-0079-6"))
GET(url=oa_url,path=my_path)
```

This function also works on a vector, which will become handy later. See the examples:

```{r}
makePath(query=letters[1:3]) # vectorize!

data_frame(doi=letters[1:3]) %>% mutate(path = makePath(doi)) # works in the tidyverse
```

## extractAvailability

We need a function to extract the availability data frame from the JSON results, as well as some other useful information such as title, if available. The problem is, the JSON results don't always have an availability field, so we can't use extract type functions. For example,


This function takes the output from `fromJSON` and extracts the availability data frame.

```{r}
extractAvailability = function(rawcontent) {
  # Test whether there is anything in the availability field
  if(length(rawcontent$data$availability)>0){
    bind_cols(data_frame(match=rawcontent$data$match),
              as_data_frame(rawcontent$data$availability),
              data_frame(
                source=rawcontent$data$meta$article$source,
                title=ifelse(length(rawcontent$data$meta$article$title)>0,rawcontent$data$meta$article$title,NA) # not always available
                ))
  }else{
    bind_cols(data_frame(match=rawcontent$data$match),url=NA)
  }
}
extractAvailability(this_content)
```

We can try using this function on a few different DOIs. Note I've converted the above example code to tidyverse style of coding:

```{r}
# OA not available
tmpquery = "10.1234/567890"
tmpraw = GET(url=oa_url,path=makePath(tmpquery))
tmpraw %>% 
  magrittr::extract2("content") %>% 
  rawToChar() %>% 
  fromJSON() %>%
  extractAvailability()

# OA available
tmpquery = "10.1007/s10278-018-0079-6"
tmpraw = GET(url=oa_url,path=makePath(tmpquery))
tmpraw %>% 
  magrittr::extract2("content") %>% 
  rawToChar() %>% 
  fromJSON() %>%
  extractAvailability()

# OA available, with title search
tmpquery = "Hello World"
tmpraw = GET(url=oa_url,path=makePath(tmpquery))
tmpraw %>% 
  magrittr::extract2("content") %>% 
  rawToChar() %>% 
  fromJSON() %>%
  extractAvailability()

# OA available, with url search; title available
tmpquery = "https://doi.org/10.1017/S0033291711000997"
tmpraw = GET(url=oa_url,path=makePath(tmpquery))
tmpraw %>% 
  magrittr::extract2("content") %>% 
  rawToChar() %>% 
  fromJSON() %>%
  extractAvailability()
```

# Put it all together

Ok, now let's use our functions to grab some data! We'll use `rcrossref` to generate some random dois:

```{r}
set.seed(100)
doi_sample <- data_frame(query = rcrossref::cr_r(sample = 100))
head(doi_sample)
```

Let's construct our queries:

```{r}
doi_sample <- doi_sample %>% 
  mutate(path = makePath(query))
head(doi_sample)
```

We don't want to overload the API, so we will add in a second delay to our `GET` function through a loop:

```{r, message=TRUE, cache = TRUE}
oabutton_raw <- vector(mode   = "list",
                       length = nrow(doi_sample))
t0 <- Sys.time()
for (i in 1:nrow(doi_sample)) {
  oabutton_raw[[i]] <- GET(url=oa_url,path=doi_sample$path[i]) %>% 
    magrittr::extract2("content") %>% 
    rawToChar() %>% 
    fromJSON()
  message(".", appendLF = FALSE)
  if(i%%50==0) print(i)
  Sys.sleep(time = 1)
}
Sys.time()-t0
```

Now let's extract our availability data:

```{r}
names(oabutton_raw) <- doi_sample$query
res <- oabutton_raw %>%
  purrr::map_df(extractAvailability,.id="query")
head(res %>% arrange(url))
```

We can join this to the query table and also search `rcrossref` for metadata.

```{r}
res <- left_join(doi_sample,res)

crossref_res <- rcrossref::cr_works(dois = res%>%pull(query)) %>% 
  magrittr::extract2("data")

res_all <- left_join(res, crossref_res, by=c("query"="doi"), suffix = c("_oabutton","_rcrossref"))

# add OA button indicator
res_all     <- res_all%>%mutate(
  oa_result_oabutton = case_when(
    is.na(source_oabutton) ~ "oa_not_found",
    !is.na(source_oabutton) ~ "oa_found")
)
```

A glimpse of the results table is shown below:

```{r}
glimpse(res_all)
```

# Summarize results

Here we can calculate how many DOIs were found to be open access, along with the source that OA button has identified.
```{r}
res_all %>% tabyl(oa_result_oabutton)%>%
  adorn_totals()%>%
  adorn_pct_formatting() %>%
  kable()


res_all %>% filter(oa_result_oabutton=="oa_found")%>%
  tabyl(source_oabutton)%>%
  adorn_totals()%>%
  adorn_pct_formatting()

```

We can visualize that result using bar charts:

```{r}
res_all %>% ggplot(aes(x=oa_result_oabutton,fill=source_oabutton)) + 
  geom_bar() + 
  theme_minimal()
```

We can also examine the metadata found with `rscrossref`. For example, here are the various work types found with rcrossref, with colors denoting no open access (grey = NA) or source of open access:

```{r}
res_all %>% ggplot(aes(x=type_rcrossref,fill=source_oabutton)) + 
  geom_bar() + 
  theme_minimal() + 
  theme(axis.text.x=element_text(angle=45, hjust = 1))
```



